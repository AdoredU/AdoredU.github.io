---
layout: post
title: Hadoop学习
tags: Hadoop 大数据 HDFS
categories: 大数据
---

* TOC
{:toc}

## 0. 介绍

1. 官网：[https://hadoop.apache.org](https://hadoop.apache.org)；

```txt
The Apache™ Hadoop® project develops open-source software for reliable, scalable, distributed computing.

The Apache Hadoop software library is a framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models. It is designed to scale up from single servers to thousands of machines, each offering local computation and storage. Rather than rely on hardware to deliver high-availability, the library itself is designed to detect and handle failures at the application layer, so delivering a highly-available service on top of a cluster of computers, each of which may be prone to failures.
```

- Java语言实现的开源框架；
- 使用简单模型处理大量数据；
- 集群、分布式处理；
- 计算、存储、高可靠；

2. 核心组件（狭义上的Hadoop）：

- HDFS：分布式文件存储系统；
- YARN：作业调度和集群资源管理框架，解决资源任务调度；
- MAPREDUCE：分布式运算编程框架，解决海量数据计算；

3. 特点：

- 扩容能力：集群；
- 成本低：单个机子要求并不高；
- 高效率：分布式，支持并发的数据处理；
- 可靠性：备份、副本，任务失败后重新执行等；

4. 集群：

```txt
Hadoop集群具体来说包含两个集群：HDFS集群和YARN集群，二者逻辑上分离，物理上常在一起。
```

- HDFS集群：负责海量数据的存储；
  - NameNode
  - DataNode
  - SecondaryNameNode
- YARN集群：负责海量数据运算时的资源调度；
  - ResourceManager
  - NodeManager

说明：mapreduce是一个分布式运算编程框架，是应用程序开发包，由用户安装规范进行程序开发后打包运行在HDFS集群上，并且收到YARN集群的资源调度管理。

## 1. 集群搭建

1.1 准备：

- 系统：ubuntu 16.04 x 3（时间统一；防火墙关闭）；

- 网络及免密配置：参考[ubuntu ssh免密配置](https://adoredu.github.io/linux/linux-ssh/)；
- jdk安装：参考[ubuntu下jdk安装](https://adoredu.github.io/java/jdk-install/)；

- 部署说明：
  - node-1：NameNode、DataNode、ResourceManager；
  - node-2：DataNode、NodeManager、SecondaryNameNode；
  - node-3：DataNode、NodeManager；

1.2 下载Hadoop：

- [3.2.1下载地址](https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-3.2.1/hadoop-3.2.1.tar.gz)；

1.3 解压（node-1）：

```shell
$: tar -zxvf 'hadoop-3.2.1.tar.gz' -C ~/
```

1.4 配置（./hadoop-3.2.1/etc/hadoop/）：

- hadoop-env.sh：

  ```txt
  export JAVA_HOME=/usr/local/jdk1.8.0_91
  ```

- core-site.xml：

  ```xml
  <!-- 指定Hadoop所使用的文件系统schema（URI），HDFS的NameNode的地址-->
  <property>
    <name>fs.defaultFS</name>
    <value>hdfs://node-1:9000</value>
  </property>
  <!-- 指定运行中产生数据的存放目录 -->
  <property>
    <name>hadoop.tmp.dir</name>
    <value>/home/gp/hadoop-3.2.1/data/hdata</value>
  </property>
  ```
  
- hdfs-site.xml：

  ```xml
  <!-- 指定HDFS副本的数量，默认3 -->
  <property>
    <name>dfs.replication</name>
    <value>2</value>
  </property>
  <property>
    <name>dfs.namenode.secondary.http-address</name>
    <value>node-2:50090</value>
  </property>
  ```

- mapred-site.xml：

  ```xml
  <!-- 指定mr运行时框架，这里指定在yarn上，默认是local -->
  <property>
    <name>mapreduce.framework.name</name>
    <value>yarn</value>
  </property>
  ```

- yarn-site.xml：

  ```xml
  <!-- 指定yarn的ResourceManager的地址 -->
  <property>
    <name>yarn.resourcemanager.hostname</name>
    <value>node-1</value>
  </property>
  <!-- NodeManager上运行的附属服务。需配置成mapredue_shuffle -->
  <property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
  </property>
  ```

- slaves（从节点主机名，新版本改名为workers）：

  ```txt
  node-1
  node-2
  node-3
  ```

- 配置环境变量（/etc/profile）：

  ```txt
  export HADOOP_HOME=/home/gp/hadoop-3.2.1
  export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
  ```

- 刷新环境变量：

  ```shell
  $: source /etc/profile
  ```
  
  说明：hadoop中一般自定义配置文件名称为\**-site.xml，对于未自定义的配置，hadoop默认的**-default.xml都有默认值。
  
  <hr />
  
  补充：终端执行`hadoop classpath`，将返回值配置到yarn-site.xml中：
  
- yarn-site.xml：

  ```xml
  <property>
    <name>yarn.application.classpath</name>
    <value>/home/gp/hadoop-3.2.1/etc/hadoop:/home/gp/hadoop-3.2.1/share/hadoop/common/lib/*:/home/gp/hadoop-3.2.1/share/hadoop/common/*:/home/gp/hadoop-3.2.1/share/hadoop/hdfs:/home/gp/hadoop-3.2.1/share/hadoop/hdfs/lib/*:/home/gp/hadoop-3.2.1/share/hadoop/hdfs/*:/home/gp/hadoop-3.2.1/share/hadoop/mapreduce/lib/*:/home/gp/hadoop-3.2.1/share/hadoop/mapreduce/*:/home/gp/hadoop-3.2.1/share/hadoop/yarn:/home/gp/hadoop-3.2.1/share/hadoop/yarn/lib/*:/home/gp/hadoop-3.2.1/share/hadoop/yarn/*</value>
  </property>
  ```

1.5 分发到node-2、node-3：

```shell
$ scp -r hadoop-3.2.1/ gp@node-2:~/
$ scp -r hadoop-3.2.1/ gp@node-3:~/
# node-2、node-3配置环境变量并刷新
```

## 2. 启动

> 启动集群需要启动HDFS和YARN两个集群。

注意：

- 首次启动HDFS时，必须对其进行初始化操作，因为此时HDFS在物理上还是不存在的。

- 初始化只在主节点执行一次；
- 格式化命令：`hdfs namenode -format`或者`hardoop namenode -format`。

2.1 单节点逐个启动：

- 主节点启动/关闭NameNode：`hadoop-daemon.sh start/stop namenode`；
- 从节点启动/关闭DataNode：`hadoop-daemon.sh start/stop datanode`；
- 主节点启动/关闭ResourceManager：`yarn-daemon.sh start/stop resourcemanager`；
- 从节点启动/关闭NodeManager：`yarn-daemon.sh start/stop nodemanager`；

2.2 一键启动：

> 需要配置workers和ssh免密。在主节点执行：

- hdfs：`${HADOOP_HOME}/sbin/start-dfs.sh` / `${HADOOP_HOME}/sbin/stop-dfs.sh`；
- yarn：`${HADOOP_HOME}/sbin/start-yarn.sh` / `${HADOOP_HOME}/sbin/stop-yarn.sh`；

说明：通过jps命令可以查看启动状态。

```shell
gp@node-1:~/hadoop-3.2.1/sbin$ start-dfs.sh 
Starting namenodes on [node-1]
node-1: WARNING: /home/gp/hadoop-3.2.1/logs does not exist. Creating.
Starting datanodes
node-3: WARNING: /home/gp/hadoop-3.2.1/logs does not exist. Creating.
node-2: WARNING: /home/gp/hadoop-3.2.1/logs does not exist. Creating.
Starting secondary namenodes [node-2]
gp@node-1:~/hadoop-3.2.1/sbin$ jps
2615 DataNode
2488 NameNode
2845 Jps
gp@node-1:~/hadoop-3.2.1/sbin$ start-yarn.sh 
Starting resourcemanager
Starting nodemanagers
gp@node-1:~/hadoop-3.2.1/sbin$ jps
2615 DataNode
2488 NameNode
3786 Jps
3326 ResourceManager
3471 NodeManager
```

2.3 查看（node-1）：

- hdfs：`http://node-1:9870`；
- yarn：`http://node-1:8088`；

2.4 体验hdfs：

- 点击utils下的'Browse the file System'，可以看到初始没有任何文件：

![image-20191016084500054](/Users/gp/Desktop/github_projects/AdoredU.github.io/_posts/assets/image-20191016084500054.png)

- 命令行执行：`hdfs dfs -ls /`，发现为空：

```shell
gp@node-1:~/software/hadoop-3.2.1/sbin$ hdfs dfs -ls /
gp@node-1:~/software/hadoop-3.2.1/sbin$ 
```

- 创建文件夹：`hdfs dfs -mkdir /hello `，刷新页面，可以看到已生成：

![image-20191016084829053](/Users/gp/Desktop/github_projects/AdoredU.github.io/_posts/assets/image-20191016084829053.png)

- 同样，执行命令也可以查看到：

```shell
gp@node-1:~/software/hadoop-3.2.1/sbin$ hdfs dfs -ls /
Found 1 items
drwxr-xr-x   - gp supergroup          0 2019-10-16 08:47 /hello
gp@node-1:~/software/hadoop-3.2.1/sbin$ hdfs dfs -mkdir -p /tmp/input
```

- 上传文件：`hdfs dfs -put wordcount.txt /tmp/input`；

```txt
This is a test
For word count
Hello world
Please sum the word For me
```

2.5 体验yarn（提交运行mapreduce程序）

- yarn首页：

![image-20191016100324957](/Users/gp/Desktop/github_projects/AdoredU.github.io/_posts/assets/image-20191016100324957.png)

- 在./hadoop-3.2.1/share/hadoop/mapreduce下官方自带测试程序hadoop-mapreduce-examples-3.2.1.jar，执行如下命令进行测试：

  ```shell
  hadoop jar hadoop-mapreduce-examples-3.2.1.jar wordcount /tmp/input /tmp/output
  ```


- 结果：

  ```shell
  gp@node-1:~/hadoop-3.2.1/sbin$ hdfs dfs -cat /tmp/output/part-r-00000
  2019-10-16 18:16:45,167 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
  For	2
  Hello	1
  Please	1
  a	1
  count	1
  is	1
  me	1
  s	1
  sum	1
  test	1
  the	1
  word	2
  world	1
  ```


## 3. HDFS

3.1 概念：

- HDFS：HDFS：Hadoop Distribute File System，Hadoop分布式文件系统。Hadoop核心组件之一，底层的分布式存储服务。
- NameNode：元数据管理。负责维护整个hdfs文件系统的目录结构，以及每个文件对应的block信息；
- DataNode：存储数据。定时向NameNode汇报自己存储的block信息；

注意：

- NameNode并不会持久化存储文件块在DataNode上的储存信息，这些信息会在服务启动时从数据节点重建（NameNode还有文件系统镜像和操作日志），因此一般NameNode所在机器需要较大内存；
- 客户的操作请求都是先由NameNode接收和处理的；
- DataNode在启动时会向NameNode上报自己存储的块信息等，且会跟NameNode维持心跳（默认3s）。块信息维持心跳默认间隔6小时；

3.2 上传流程：
![image-20191021083101163](/Users/gp/Desktop/github_projects/AdoredU.github.io/_posts/assets/image-20191021083101163.png)

3.3 下载流程：

1. 客户端向NameNode发起请求；
2. NameNode按一定排序规则，视情况返回block的部分或全部列表，包含每个block的副本信息；
3. 客户端优先从返回列表靠前的DataNode上获取数据；
4. 建立Socket Stream，并行的读取block信息。若读取完列表的block信息，文件读取还没有完，则继续向NameNode获取下一批block信息；
5. 每读取完一个block都会进行checksum验证，如果读取DataNode时出现错误，客户的会通知NameNode，然后再向下一个副本读取；
6. 最终读取完的block会在客户的组成完整文件；

3.4 命令行操作：

> hdfs命令操作不仅支持HDFS文件系统，还支持本地FS、HFTP FS、S3 FS等。URI格式为scheme://authrity/path。HDFS的scheme为hdfs，本地fs的scheme为file。scheme和authority是可选的，如果未指定，使用默认方案。示例：

- `hadoop fs -ls hdfs://node-1:9000/  # hdfs文件系统`；
- `hadoop fs -ls file:///root/  # 本地fs系统`；

说明：`hadoop fs <args>` 和`hdfs dfs <args>`效果一样。前者为新版本中命令，推荐使用。

常用命令：

- -ls：参数-R表示递归展示，-h优化文件大小展示；
- -mkdir：-p表示多级创建；
- -put：-f表示覆盖同名文件；
- -get：-f同get；
- -appendToFile：追加到文件末尾；
- -cat：同cat；
- -tail：文件最后一千字节显示到stdout；
- -chgrp：修改组；
- -chmod：修改权限；
- -chown：修改拥有者；
- -copyFromLocal：同put； 
- -copyToLocal：同get；
- -cp：复制；
- -mv：移动；
- -getmerge：合并。如：`hadoop fs -getmerge  /aaa/log.* ./log.sum`；
- -rm：-r表示递归删除；
- -df：查看磁盘信息；
- -du：显示目录中所有文件大小；
- -setrep：改变副本个数。-R表示递归改变子文件：`hadoop fs -setrep -w 3 -R /tmp`

3.5 应用开发（Java）

> HDFS的应用开发一般就是通过提供的api构造客户端对象，进行文件操作。

1. 引入pom依赖：

```xml
<dependencies>
    <dependency>
        <groupId>org.apache.hadoop</groupId>
        <artifactId>hadoop-common</artifactId>
        <version>3.2.1</version>
  </dependency>
    <dependency>
        <groupId>org.apache.hadoop</groupId>
        <artifactId>hadoop-hdfs</artifactId>
        <version>3.2.1</version>
  </dependency>
    <dependency>
        <groupId>org.apache.hadoop</groupId>
        <artifactId>hadoop-client</artifactId>
        <version>3.2.1</version>
  </dependency>
</dependencies>
```

2. 使用到类：

- Configuration：封装客户端或服务端的配置；

- FileSystem：文件系统，操作文件，通过静态方法`get()`获取对象：

  `FileSystem fs = FileSystem.get(conf)`

  该方法从conf中的一个参数fs.getDefaultFS的配置值判断具体是什么类型的文件系统。如果配置中没有指定该值，且classpath下没有相应配置，则该值使用hadoop的jar包中core-default.xml，默认值为file:///，此时获取的不是DistributedFileSystem的实例，而是一个本地文件系统的客户端对象。

3. 代码：

```java
package com.adoredu.hdfs;

import org.apache.commons.io.IOUtils;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FSDataOutputStream;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;

import java.io.FileInputStream;
import java.net.URI;

public class HDFSTestClient {

    public static void main(String[] args) throws Exception {
        Configuration conf = new Configuration();
        conf.set("fs.defaultFS", "hdfs://node-1:9000");
        // 设置客户的身份
//        System.setProperty("HADOOP_USER_NAME", "gp");
        FileSystem fs = FileSystem.get(conf);
        // 也可以通过如下方式指定文件系统类型并且设置用户身份
        // FileSystem fs = FileSystem.get(new URI("hdfs://node-1:9000"), conf, "gp");
        // 创建一个目录
//        fs.create(new Path("/helloByJava"));
        // 下载文件
//        fs.copyToLocalFile(new Path("/tmp/input/wordcount.txt"), new Path("/Users/gp/Desktop/tmp"));
        // 下载后会在对应路径下有wordcount.txt和一个标识成功的.wordcount.txt.crc文件

        // 流式操作，更底层的操作
        // 将本地文件上传到hdfs
        FSDataOutputStream outputStream = fs.create(new Path("/test.txt"), true);
        FileInputStream inputStream = new FileInputStream("/Users/gp/Desktop/tmp/test.txt");
        IOUtils.copy(inputStream, outputStream);

        // 关闭连接
        fs.close();
    }
}
```

代码位置：[https://github.com/AdoredU/hadoop-demo](https://github.com/AdoredU/hadoop-demo)。

